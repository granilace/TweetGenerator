{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KXhzjBIi-vky"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import twitter\n",
    "\n",
    "from fastai.text import TextLMDataBunch, URLs\n",
    "from fastai.text import language_model_learner\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "\n",
    "random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2tvMnSRuS1n"
   },
   "source": [
    "## Loading history of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pku8j6zx15tQ"
   },
   "source": [
    "You will need to create your own developer account here https://developer.twitter.com/en/apps and register a Twitter application to get neccessary tokens and save them in *credentials.json* in JSON format or put directly in code bellow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BW5oVa71uWV9"
   },
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    splited = tweet.split(' ')\n",
    "    for i, word in enumerate(splited):\n",
    "        if 'http' in word or 't.co' in word:\n",
    "            splited[i] = 'HYPERLINK'\n",
    "    return ' '.join(splited)\n",
    "\n",
    "def remove_nonascii(tweet):\n",
    "    return ''.join([char if ord(char) < 128 else '' for char in tweet])\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    processed = remove_links(tweet)\n",
    "    processed = remove_nonascii(processed)\n",
    "    return processed\n",
    "\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "\n",
    "class TweetLoader:\n",
    "    def __init__(self, credentials, name):\n",
    "        self.name = name\n",
    "        self.api = twitter.Api(**credentials)\n",
    "        self.api.VerifyCredentials()\n",
    "\n",
    "\n",
    "    def get_last_tweet_id(self):\n",
    "        statuses = self.api.GetUserTimeline(\n",
    "            screen_name=self.name,\n",
    "            count=1,\n",
    "            include_rts=False\n",
    "        )\n",
    "        first_tweet = statuses[0]\n",
    "        return first_tweet.id\n",
    "\n",
    "    def load_batch(self, id):\n",
    "        statuses = self.api.GetUserTimeline(\n",
    "            screen_name=self.name,\n",
    "            count=BATCH_SIZE,\n",
    "            include_rts=False,\n",
    "            max_id=id\n",
    "        )\n",
    "        tweets = [status.full_text for status in statuses]\n",
    "        last_tweet = statuses[-1]\n",
    "        return tweets, last_tweet.id\n",
    "\n",
    "    def load(self):\n",
    "        prev_id = None\n",
    "        id = self.get_last_tweet_id()\n",
    "        raw_tweets = []\n",
    "        batch_tweets, id = self.load_batch(id)\n",
    "        while id != prev_id:\n",
    "            raw_tweets += batch_tweets[1:]\n",
    "            prev_id = id\n",
    "            batch_tweets, id = self.load_batch(prev_id)\n",
    "        clean_data = list(map(clean_tweet, raw_tweets))\n",
    "        return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "sp-ph7M3-D3m",
    "outputId": "1d7cf1bd-ac7f-460b-e3f9-c9af5c3c6f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2752 tweets\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_CREDENTIALS = 'credentials.json'\n",
    "\n",
    "if os.path.isfile(PATH_TO_CREDENTIALS):\n",
    "    with open(PATH_TO_CREDENTIALS, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "else:\n",
    "    raise FileNotFoundError('Please save tokens in `{}`'.format(PATH_TO_CREDENTIALS))\n",
    "\n",
    "tweet_loader = TweetLoader(credentials, name='realDonaldTrump')\n",
    "real_tweets = tweet_loader.load()\n",
    "\n",
    "print('Loaded {} tweets'.format(len(real_tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JO0waY52DUws"
   },
   "source": [
    "## Generating tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YW8LTmdl_TZ7"
   },
   "outputs": [],
   "source": [
    "# Inspired by https://github.com/paraschopra/generating-text-small-corpus\n",
    "\n",
    "class TweetGenerator:\n",
    "    def __init__(self, data, dropout=0.5):\n",
    "        self.dropout = 0.5\n",
    "        train_data, validation_data = train_test_split(\n",
    "            list(map(lambda x: x.lower(), data)),\n",
    "            test_size=0.05,\n",
    "            random_state=1\n",
    "        )\n",
    "        self.train_df = pd.DataFrame({'tweet': train_data})\n",
    "        self.validation_df = pd.DataFrame({'tweet': validation_data})\n",
    "        self.trained = False\n",
    "  \n",
    "    def train(self, epochs=8, batch_size=32):\n",
    "        self.data_lm = TextLMDataBunch.from_df(\n",
    "            'data',\n",
    "            self.train_df,\n",
    "            self.validation_df,\n",
    "            text_cols='tweet',\n",
    "            bs=batch_size\n",
    "        )\n",
    "        if not self.trained:\n",
    "            self.model = language_model_learner(self.data_lm, pretrained_model=URLs.WT103, drop_mult=self.dropout)\n",
    "            self.model.fit_one_cycle(1, 1e-2)\n",
    "            self.model.unfreeze()\n",
    "            self.model.fit_one_cycle(1, 1e-3)\n",
    "            self.trained = True\n",
    "            self.model.fit(epochs, lr=1e-3, wd=1e-7)\n",
    "    \n",
    "    def generate(self, count=10, max_words=70):\n",
    "        generated_tweets = []\n",
    "        while len(generated_tweets) < count:\n",
    "            raw_generated = self.model.predict(\"xxbos\", n_words=max_words, temperature=0.8)\n",
    "            raw_tweets = raw_generated.split(\"xxbos \")[1:]\n",
    "            for tweet in raw_tweets:\n",
    "                tweet = tweet.replace('hyperlink', '')[:-1]\n",
    "                if tweet:\n",
    "                    generated_tweets.append(tweet)\n",
    "        return generated_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "Y2tPso4rAIdO",
    "outputId": "5e34244e-85c2-4b3b-86e3-0e2a022d2445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the united states is with great progress from being corrupt on china , but i m looking forward to doing very well . but then it does , and can not do , it is dumb against china . this is the worst number they have ever seen . there are no barriers to china , and all over the world , yet i ve always been very positive abou\n",
      "\n",
      "the u.s . , however , is not strong on trade , the economy and the economy . we have the right to leakers and the border ?\n",
      "\n",
      "today , we have in the 2017 presidential election in california . we won in november and be a great senator for ohio . when we have meeting and vote for governor david j. trump , you will be leaving th\n",
      "\n",
      "the washington post had some big quotes since the election for governor of the great state of michigan . if you have to wait until you see your speech , they will be free to do so . but did nt care about that money . it is a really big job !\n",
      "\n",
      "the fake news is on frame . no official news was leaked . the story i\n"
     ]
    }
   ],
   "source": [
    "tweet_generator = TweetGenerator(real_tweets)\n",
    "tweet_generator.train(epochs=3, batch_size=32)\n",
    "tweet_generator.train(epochs=2, batch_size=64)\n",
    "\n",
    "generated_tweets = tweet_generator.generate(5)\n",
    "print('\\n'.join(generated_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjdCUrUEYHQm"
   },
   "source": [
    "## Capitalizing words and cleaning sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrlP6dPqYXxj"
   },
   "source": [
    "Let's train char-RNN for proper word capitalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MU8T8Tl_ZNgz"
   },
   "outputs": [],
   "source": [
    "PAD_token = 2\n",
    "EOS_token = 1 \n",
    "UNK_token = 0\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char2index = {'UNK': UNK_token, 'EOS': EOS_token, 'PAD': PAD_token}\n",
    "        self.num_chars = 3  # Count PAD, EOS, UNK\n",
    "\n",
    "    def add_tweet(self, tweet):\n",
    "        for char in tweet:\n",
    "            self.add_char(char.lower())\n",
    "\n",
    "    def add_char(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.num_chars\n",
    "            self.num_chars += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Huqha9uVAziY"
   },
   "outputs": [],
   "source": [
    "vocabulary = Vocabulary()\n",
    "for tweet in real_tweets:\n",
    "    vocabulary.add_tweet(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtVRDkGOt7s7"
   },
   "outputs": [],
   "source": [
    "def prettify_tweet(tweet):\n",
    "    while tweet.find('xxrep') != -1:\n",
    "        rep_pos = tweet.find('xxrep')\n",
    "        try:\n",
    "            count = int(tweet[rep_pos + len('xxrep') + 1])\n",
    "            char_to_rep = tweet[rep_pos + len('xxrep ') + 2]\n",
    "            tweet = tweet[:rep_pos] + char_to_rep * count + tweet[rep_pos + len('xxrep ') + 3:]\n",
    "        except:\n",
    "            tweet = tweet.replace('xxrep', '')\n",
    "    prepositions =['?', '!', ',', '.', '\\'', '”', 'n\\'t', '%', '$', ')', ':', '& ']\n",
    "    postpositions = ['$', '#', '“', '(']\n",
    "    for char in prepositions:\n",
    "        tweet = tweet.replace(' ' + char, char)\n",
    "    for char in postpositions:\n",
    "        tweet = tweet.replace(' ' + char, char)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTvrL-vpA0Eb"
   },
   "outputs": [],
   "source": [
    "def get_indexes(voc, sentence):\n",
    "    return [voc.char2index.get(char.lower(), UNK_token) for char in sentence]\n",
    "\n",
    "def padd_batch(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def construct_input_batch(input_sentences, voc):\n",
    "    indexes_batch = [get_indexes(voc, sentence) for sentence in input_sentences]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padded_input = padd_batch(indexes_batch)\n",
    "    padded_input = torch.LongTensor(padded_input)\n",
    "    return padded_input, lengths\n",
    "\n",
    "def construct_target_batch(target_batch):\n",
    "    padded_target = np.array(padd_batch(target_batch))\n",
    "    mask = np.array(padded_target != PAD_token, dtype='int')\n",
    "    mask = torch.FloatTensor(mask)\n",
    "    padded_target = torch.FloatTensor(padded_target)\n",
    "    return padded_target, mask\n",
    "\n",
    "def construct_batch(voc, tweets):\n",
    "    tweets.sort(key=lambda x: len(x), reverse=True)\n",
    "    inp_batch, target_batch = [], []\n",
    "    for tweet in tweets:\n",
    "        inp_batch.append(tweet)\n",
    "        target_batch.append(list(map(lambda x: int(x.isupper()), tweet)))\n",
    "    inp_batch, lengths = construct_input_batch(inp_batch, voc)\n",
    "    target_batch, mask = construct_target_batch(target_batch)\n",
    "    return inp_batch, lengths, target_batch, mask\n",
    "\n",
    "class CaseRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(CaseRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            n_layers,\n",
    "            dropout=(0 if n_layers == 1 else dropout),\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        outputs, hidden = self.gru(embedded, hidden)\n",
    "        outputs = self.fc(outputs)\n",
    "        outputs = outputs.view((input_lengths[0], -1))\n",
    "        outputs = self.sigmoid(outputs)\n",
    "        return outputs, hidden\n",
    "  \n",
    "    def capitalize(self, tweets, threshold=0.6):\n",
    "        pretty_tweets = list(map(prettify_tweet, tweets))\n",
    "        inp, lengths, target, mask = construct_batch(vocabulary, pretty_tweets)\n",
    "        outputs, _ = self.forward(inp.to(device), lengths)\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "  \n",
    "        capitalized_tweets = []\n",
    "        for i, tweet in enumerate(pretty_tweets):\n",
    "            is_upper = outputs[i] > threshold\n",
    "            capitalized_tweet = ''\n",
    "            for j, char in enumerate(tweet):\n",
    "                if is_upper[j]:\n",
    "                    capitalized_tweet += char.upper()\n",
    "                else:\n",
    "                    capitalized_tweet += char\n",
    "            capitalized_tweets.append(capitalized_tweet)\n",
    "        return capitalized_tweets\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "def masked_loss(output, target, mask):\n",
    "    loss =  mask * (-target * torch.log2(outputs + EPS) - (1 - target) * torch.log2(1 - outputs + EPS))\n",
    "    average_loss = loss.sum(0).mean()\n",
    "    return average_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VExungG_A1pX"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "HIDDEN_SIZE = 70\n",
    "\n",
    "embedding = nn.Embedding(vocabulary.num_chars, HIDDEN_SIZE)\n",
    "\n",
    "tweet_capitalizer = CaseRNN(HIDDEN_SIZE, embedding, n_layers=2, dropout=0.3)\n",
    "tweet_capitalizer.to(device)\n",
    "optimizer = optim.Adam(tweet_capitalizer.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnjCXo-xdJCs"
   },
   "outputs": [],
   "source": [
    "loss_history = []\n",
    "\n",
    "N_ITERATIONS = 800\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    inp, lengths, target, mask = construct_batch(vocabulary, [random.choice(real_tweets) for _ in range(48)])\n",
    "    inp = inp.to(device)\n",
    "    target = target.to(device)\n",
    "    mask = mask.to(device)\n",
    "  \n",
    "    optimizer.zero_grad()\n",
    "    outputs, _ = tweet_capitalizer(inp, lengths)\n",
    "    loss = masked_loss(outputs, target, mask)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "    loss_history.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "colab_type": "code",
    "id": "7H35OA6YFtHO",
    "outputId": "e053d7c4-4a94-4349-c388-0edb5be9d65b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The United States is with great progress from being corrupt on China, but I m looking forward to doing very well. But then it does, and can not do, it is dumb against China. This is the worst number they have ever seen. There are no barriers to China, and all over the world, yet I ve always been very positive abou',\n",
       " 'The Washington post had some big quotes since the Election for Governor of the great state of Michigan. If you have to wait until you see your speech, they will be free to do so. But did nt care about that money. It is a really big job!',\n",
       " 'Today, we have in the 2017 Presidential Election in California. We won in November and be a great Senator for Ohio. When we have meeting and vote for Governor David J. Trump, you will be leaving th',\n",
       " 'The U.S., however, is not strong on trade, the economy and the economy. We have the right to leakers and the Border?',\n",
       " 'The Fake News is on frame. No official News was leaked. The story I']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_capitalizer.capitalize(generated_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_FQI1-x65oF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tweet_generator.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
